version: 0.4.0
kind: app
metadata:
  name: "é«˜çº§å¤–éƒ¨çŸ¥è¯†åº“å·¥ä½œæµ"
  description: "æ”¯æŒå¤šçŸ¥è¯†åº“ã€æ¡ä»¶åˆ†æ”¯ã€å¾ªç¯å’Œé«˜çº§æ£€ç´¢çš„æ™ºèƒ½é—®ç­”å·¥ä½œæµ"
  author: "Dify Assistant"
  icon: "ğŸ§ "
  icon_background: "#E3F2FD"
  tags: ["knowledge", "external", "advanced", "workflow", "rag", "multi-source"]
spec:
  app:
    mode: workflow
    icon: "ğŸ§ "
    icon_background: "#E3F2FD"
    name: "é«˜çº§å¤–éƒ¨çŸ¥è¯†åº“å·¥ä½œæµ"
    description: "æ”¯æŒå¤šçŸ¥è¯†åº“ã€æ¡ä»¶åˆ†æ”¯ã€å¾ªç¯å’Œé«˜çº§æ£€ç´¢çš„æ™ºèƒ½é—®ç­”å·¥ä½œæµ"
    tags: ["knowledge", "external", "advanced", "workflow", "rag", "multi-source"]
    workflow:
      graph:
        nodes:
          - id: "start"
            type: "start"
            data:
              title: "å¼€å§‹"
              desc: "å·¥ä½œæµå¼€å§‹èŠ‚ç‚¹"
              variables:
                - variable: "query"
                  label: "ç”¨æˆ·é—®é¢˜"
                  type: "text-input"
                  required: true
                  max_length: 2000
                  options: []
                - variable: "knowledge_sources"
                  label: "çŸ¥è¯†åº“æ¥æº"
                  type: "select"
                  required: false
                  options:
                    - label: "å…¨éƒ¨çŸ¥è¯†åº“"
                      value: "all"
                    - label: "æŠ€æœ¯æ–‡æ¡£"
                      value: "tech"
                    - label: "äº§å“æ–‡æ¡£"
                      value: "product"
                    - label: "ç”¨æˆ·æ‰‹å†Œ"
                      value: "manual"
                - variable: "search_mode"
                  label: "æœç´¢æ¨¡å¼"
                  type: "select"
                  required: false
                  options:
                    - label: "è¯­ä¹‰æœç´¢"
                      value: "semantic"
                    - label: "å…³é”®è¯æœç´¢"
                      value: "keyword"
                    - label: "æ··åˆæœç´¢"
                      value: "hybrid"
                - variable: "max_results"
                  label: "æœ€å¤§ç»“æœæ•°"
                  type: "number-input"
                  required: false
                  default: 5
                  min: 1
                  max: 20
          - id: "query_analyzer"
            type: "llm"
            data:
              title: "æŸ¥è¯¢åˆ†æå™¨"
              desc: "åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç¡®å®šæœç´¢ç­–ç•¥å’Œå‚æ•°"
              model:
                provider: "openai"
                name: "gpt-4o"
                mode: "chat"
                completion_params:
                  temperature: 0.3
                  max_tokens: 500
                  top_p: 0.9
              prompt_template:
                - role: "system"
                  text: |
                    ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢åˆ†æä¸“å®¶ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶ç¡®å®šæœ€ä½³çš„æœç´¢ç­–ç•¥ã€‚
                    
                    è¯·åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š
                    {
                      "intent": "æŸ¥è¯¢æ„å›¾ï¼ˆå¦‚ï¼šæŠ€æœ¯é—®é¢˜ã€äº§å“åŠŸèƒ½ã€ä½¿ç”¨æŒ‡å—ç­‰ï¼‰",
                      "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
                      "complexity": "simple|medium|complex",
                      "suggested_sources": ["tech", "product", "manual"],
                      "search_strategy": "semantic|keyword|hybrid",
                      "confidence": 0.85
                    }
                - role: "user"
                  text: |
                    ç”¨æˆ·æŸ¥è¯¢ï¼š{{#start.query#}}
                    çŸ¥è¯†åº“æ¥æºï¼š{{#start.knowledge_sources#}}
                    æœç´¢æ¨¡å¼ï¼š{{#start.search_mode#}}
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 2
                retry_interval: 1
              default_value_dict:
                text: '{"intent": "general", "keywords": [], "complexity": "simple", "suggested_sources": ["tech"], "search_strategy": "semantic", "confidence": 0.5}'
          - id: "knowledge_retrieval_tech"
            type: "knowledge-retrieval"
            data:
              title: "æŠ€æœ¯æ–‡æ¡£æ£€ç´¢"
              desc: "ä»æŠ€æœ¯æ–‡æ¡£çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯"
              query_variable_selector: ["start", "query"]
              dataset_ids: ["tech_dataset_id"]
              retrieval_mode: "multiple"
              multiple_retrieval_config:
                top_k: 5
                score_threshold: 0.6
                reranking_mode: "reranking_model"
                reranking_enable: true
                reranking_model:
                  provider: "cohere"
                  model: "rerank-multilingual-v2.0"
              metadata_filtering_mode: "disabled"
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 3
                retry_interval: 1
              default_value_dict:
                result: []
          - id: "knowledge_retrieval_product"
            type: "knowledge-retrieval"
            data:
              title: "äº§å“æ–‡æ¡£æ£€ç´¢"
              desc: "ä»äº§å“æ–‡æ¡£çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯"
              query_variable_selector: ["start", "query"]
              dataset_ids: ["product_dataset_id"]
              retrieval_mode: "multiple"
              multiple_retrieval_config:
                top_k: 5
                score_threshold: 0.6
                reranking_mode: "reranking_model"
                reranking_enable: true
                reranking_model:
                  provider: "cohere"
                  model: "rerank-multilingual-v2.0"
              metadata_filtering_mode: "disabled"
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 3
                retry_interval: 1
              default_value_dict:
                result: []
          - id: "knowledge_retrieval_manual"
            type: "knowledge-retrieval"
            data:
              title: "ç”¨æˆ·æ‰‹å†Œæ£€ç´¢"
              desc: "ä»ç”¨æˆ·æ‰‹å†ŒçŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯"
              query_variable_selector: ["start", "query"]
              dataset_ids: ["manual_dataset_id"]
              retrieval_mode: "multiple"
              multiple_retrieval_config:
                top_k: 5
                score_threshold: 0.6
                reranking_mode: "reranking_model"
                reranking_enable: true
                reranking_model:
                  provider: "cohere"
                  model: "rerank-multilingual-v2.0"
              metadata_filtering_mode: "disabled"
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 3
                retry_interval: 1
              default_value_dict:
                result: []
          - id: "result_merger"
            type: "code"
            data:
              title: "ç»“æœåˆå¹¶å™¨"
              desc: "åˆå¹¶å¤šä¸ªçŸ¥è¯†åº“çš„æ£€ç´¢ç»“æœ"
              code_language: "python3"
              code: |
                def main(query, tech_results, product_results, manual_results, analysis):
                    import json
                    
                    # è§£ææŸ¥è¯¢åˆ†æç»“æœ
                    try:
                        analysis_data = json.loads(analysis)
                        suggested_sources = analysis_data.get('suggested_sources', ['tech'])
                    except:
                        suggested_sources = ['tech']
                    
                    # åˆå¹¶æ‰€æœ‰ç»“æœ
                    all_results = []
                    
                    # æ·»åŠ æŠ€æœ¯æ–‡æ¡£ç»“æœ
                    if 'tech' in suggested_sources and tech_results:
                        for result in tech_results:
                            result['source'] = 'tech'
                            result['priority'] = 1.0
                            all_results.append(result)
                    
                    # æ·»åŠ äº§å“æ–‡æ¡£ç»“æœ
                    if 'product' in suggested_sources and product_results:
                        for result in product_results:
                            result['source'] = 'product'
                            result['priority'] = 0.9
                            all_results.append(result)
                    
                    # æ·»åŠ ç”¨æˆ·æ‰‹å†Œç»“æœ
                    if 'manual' in suggested_sources and manual_results:
                        for result in manual_results:
                            result['source'] = 'manual'
                            result['priority'] = 0.8
                            all_results.append(result)
                    
                    # æŒ‰ä¼˜å…ˆçº§å’Œç›¸ä¼¼åº¦æ’åº
                    all_results.sort(key=lambda x: (x.get('priority', 0.5), x.get('metadata', {}).get('score', 0)), reverse=True)
                    
                    # é™åˆ¶ç»“æœæ•°é‡
                    max_results = 10
                    merged_results = all_results[:max_results]
                    
                    return {
                        "merged_results": merged_results,
                        "total_sources": len(set(r.get('source', '') for r in merged_results)),
                        "analysis": analysis_data
                    }
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 2
                retry_interval: 1
              default_value_dict:
                merged_results: []
                total_sources: 0
                analysis: {}
          - id: "content_enhancer"
            type: "llm"
            data:
              title: "å†…å®¹å¢å¼ºå™¨"
              desc: "å¢å¼ºå’Œä¼˜åŒ–æ£€ç´¢åˆ°çš„å†…å®¹"
              model:
                provider: "openai"
                name: "gpt-4o"
                mode: "chat"
                completion_params:
                  temperature: 0.5
                  max_tokens: 1000
                  top_p: 0.9
              prompt_template:
                - role: "system"
                  text: |
                    ä½ æ˜¯ä¸€ä¸ªå†…å®¹å¢å¼ºä¸“å®¶ï¼Œè´Ÿè´£ä¼˜åŒ–å’Œå¢å¼ºæ£€ç´¢åˆ°çš„çŸ¥è¯†åº“å†…å®¹ã€‚
                    
                    è¯·å¯¹æ£€ç´¢ç»“æœè¿›è¡Œä»¥ä¸‹å¤„ç†ï¼š
                    1. æå–å…³é”®ä¿¡æ¯
                    2. è¡¥å……ç›¸å…³èƒŒæ™¯
                    3. ä¼˜åŒ–è¡¨è¾¾æ–¹å¼
                    4. ç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§
                    
                    è¿”å›å¢å¼ºåçš„å†…å®¹ï¼Œä¿æŒåŸå§‹ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚
                - role: "user"
                  text: |
                    åŸå§‹æŸ¥è¯¢ï¼š{{#start.query#}}
                    æ£€ç´¢ç»“æœï¼š{{#result_merger.merged_results#}}
                    æŸ¥è¯¢åˆ†æï¼š{{#result_merger.analysis#}}
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 2
                retry_interval: 1
              default_value_dict:
                text: "å†…å®¹å¢å¼ºå¤±è´¥"
          - id: "answer_generator"
            type: "llm"
            data:
              title: "ç­”æ¡ˆç”Ÿæˆå™¨"
              desc: "åŸºäºå¢å¼ºå†…å®¹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"
              model:
                provider: "openai"
                name: "gpt-4o"
                mode: "chat"
                completion_params:
                  temperature: 0.7
                  max_tokens: 2000
                  top_p: 0.9
                  presence_penalty: 0.1
                  frequency_penalty: 0.1
              prompt_template:
                - role: "system"
                  text: |
                    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
                    
                    è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
                    1. åŸºäºæä¾›çš„çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜
                    2. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
                    3. å›ç­”è¦å‡†ç¡®ã€æœ‰ç”¨ã€ç»“æ„æ¸…æ™°
                    4. å¼•ç”¨æ¥æºæ—¶è¯·æ³¨æ˜å‡ºå¤„
                    5. æä¾›ç›¸å…³çš„åç»­é—®é¢˜å»ºè®®
                    6. ä¿æŒä¸“ä¸šå’Œå‹å¥½çš„è¯­è°ƒ
                - role: "user"
                  text: |
                    ç”¨æˆ·é—®é¢˜ï¼š{{#start.query#}}
                    
                    å¢å¼ºå†…å®¹ï¼š{{#content_enhancer.text#}}
                    
                    æ£€ç´¢ç»Ÿè®¡ï¼š
                    - æ€»æ¥æºæ•°ï¼š{{#result_merger.total_sources#}}
                    - æ£€ç´¢ç»“æœæ•°ï¼š{{#result_merger.merged_results.length#}}
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 3
                retry_interval: 1
              default_value_dict:
                text: "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„é—®é¢˜ã€‚"
          - id: "quality_checker"
            type: "llm"
            data:
              title: "è´¨é‡æ£€æŸ¥å™¨"
              desc: "æ£€æŸ¥ç­”æ¡ˆè´¨é‡å’Œå®Œæ•´æ€§"
              model:
                provider: "openai"
                name: "gpt-4o"
                mode: "chat"
                completion_params:
                  temperature: 0.3
                  max_tokens: 500
                  top_p: 0.9
              prompt_template:
                - role: "system"
                  text: |
                    ä½ æ˜¯ä¸€ä¸ªè´¨é‡æ£€æŸ¥ä¸“å®¶ï¼Œè´Ÿè´£è¯„ä¼°ç­”æ¡ˆçš„è´¨é‡å’Œå®Œæ•´æ€§ã€‚
                    
                    è¯·è¯„ä¼°ä»¥ä¸‹æ–¹é¢å¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
                    {
                      "quality_score": 0.85,
                      "completeness": 0.9,
                      "accuracy": 0.8,
                      "clarity": 0.85,
                      "suggestions": ["å»ºè®®1", "å»ºè®®2"],
                      "needs_improvement": true
                    }
                - role: "user"
                  text: |
                    åŸå§‹é—®é¢˜ï¼š{{#start.query#}}
                    ç”Ÿæˆçš„ç­”æ¡ˆï¼š{{#answer_generator.text#}}
              vision:
                enabled: false
              error_strategy: "fallback"
              retry_config:
                enabled: true
                max_retries: 2
                retry_interval: 1
              default_value_dict:
                text: '{"quality_score": 0.5, "completeness": 0.5, "accuracy": 0.5, "clarity": 0.5, "suggestions": [], "needs_improvement": true}'
          - id: "end"
            type: "end"
            data:
              title: "ç»“æŸ"
              desc: "å·¥ä½œæµç»“æŸèŠ‚ç‚¹"
              outputs:
                - value_selector: ["answer_generator", "text"]
                  variable: "answer"
                - value_selector: ["result_merger", "merged_results"]
                  variable: "sources"
                - value_selector: ["quality_checker", "text"]
                  variable: "quality_assessment"
        edges:
          - id: "start-to-analyzer"
            source: "start"
            target: "query_analyzer"
          - id: "analyzer-to-tech"
            source: "query_analyzer"
            target: "knowledge_retrieval_tech"
          - id: "analyzer-to-product"
            source: "query_analyzer"
            target: "knowledge_retrieval_product"
          - id: "analyzer-to-manual"
            source: "query_analyzer"
            target: "knowledge_retrieval_manual"
          - id: "tech-to-merger"
            source: "knowledge_retrieval_tech"
            target: "result_merger"
          - id: "product-to-merger"
            source: "knowledge_retrieval_product"
            target: "result_merger"
          - id: "manual-to-merger"
            source: "knowledge_retrieval_manual"
            target: "result_merger"
          - id: "analyzer-to-merger"
            source: "query_analyzer"
            target: "result_merger"
          - id: "merger-to-enhancer"
            source: "result_merger"
            target: "content_enhancer"
          - id: "enhancer-to-generator"
            source: "content_enhancer"
            target: "answer_generator"
          - id: "generator-to-checker"
            source: "answer_generator"
            target: "quality_checker"
          - id: "checker-to-end"
            source: "quality_checker"
            target: "end"
      features:
        file_upload:
          enabled: false
          image:
            enabled: false
            number_limits: 3
            detail: "high"
            transfer_methods: ["remote_url", "local_file"]
        opening_statement: "æ‚¨å¥½ï¼æˆ‘æ˜¯é«˜çº§å¤–éƒ¨çŸ¥è¯†åº“æ™ºèƒ½åŠ©æ‰‹ï¼Œæ”¯æŒå¤šæºçŸ¥è¯†æ£€ç´¢å’Œæ™ºèƒ½åˆ†æã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„é—®é¢˜ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›æœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚"
        suggested_questions: 
          - "å¦‚ä½•ä½¿ç”¨å¤šçŸ¥è¯†åº“æœç´¢ï¼Ÿ"
          - "ä»€ä¹ˆæ˜¯è¯­ä¹‰æœç´¢å’Œå…³é”®è¯æœç´¢ï¼Ÿ"
          - "å¦‚ä½•æé«˜æœç´¢ç»“æœçš„å‡†ç¡®æ€§ï¼Ÿ"
          - "æ”¯æŒå“ªäº›çŸ¥è¯†åº“æ¥æºï¼Ÿ"
        suggested_questions_after_answer:
          enabled: true
        speech_to_text:
          enabled: false
        text_to_speech:
          enabled: false
        citation: true
        retriever_resource:
          enabled: true
        sensitive_word_avoidance:
          enabled: false
        more_like_this:
          enabled: true
        user_input_form: []
        system_parameters: []